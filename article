In software engineering, a software development methodology also known as
a system development methodology, software development life cycle, software
development process, software process is a splitting of software development
work into distinct phases or stages containing activities with the intent
of better planning and management. It is often considered a subset of the
systems development life cycle. The methodology may include the
predefinition of specific deliverables and artifacts that are created and
completed by a project team to develop or maintain an application. Common
methodologies include waterfall, prototyping, iterative and incremental
development, spiral development, rapid application development, extreme
programming and various types of agile methodology. Some people consider a
life cycle model a more general term for a category of methodologies and a
software development process a more specific term to refer to a specific
process chosen by a specific organization. For example, there are many
specific software development processes that fit the spiral life cycle
model. A variety of such frameworks have evolved over the years, each with
its own recognized strengths and weaknesses.
One software development methodology framework is not necessarily suitable
for use by all projects. Each of the available methodology frameworks are
best suited to specific kinds of projects, based on various technical,
organizational, project and team considerations.
Software development organizations implement process methodologies to ease
the process of development. Sometimes, contractors may require methodologies
employed, an example is the U.S. defense industry, which requires a rating
based on process models to obtain contracts. The international standard for
describing the method of selecting, implementing and monitoring the life
cycle for software is certified. A decades long goal has been to find
repeatable, predictable processes that improve productivity and quality.
Some try to systematize or formalize the seemingly unruly task of designing
software. Others apply project management techniques to designing software.
Without effective project management, software projects can easily be
delivered late or over budget. With large numbers of software projects not
meeting their expectations in terms of functionality, cost, or delivery
schedule, it is effective project management that appears to be lacking.
Organizations may create a Software Engineering Process Group SEPG, which
is the focal point for process improvement. Composed of line practitioners
who have varied skills, the group is at the center of the collaborative
effort of everyone in the organization who is involved with software
engineering process improvement. A particular development team may also
agree to programming environment details, such as which integrated
development environment is used, and one or more dominant programming
paradigms, programming style rules, or choice of specific software libraries
or software frameworks. These details are generally not dictated by the
choice of model or general methodology. History. The software development
methodology also known as SDM framework didn't emerge until the sixties.
According to Elliott two thousand four the systems development life cycle SDLC
can be
considered to be the oldest formalized methodology framework for building
information systems. The main idea of the SDLC has been to pursue the
development of information systems in a very deliberate, structured and
methodical way, requiring each stage of the life cycle from inception of
the idea to delivery of the final system to be carried out rigidly and
sequentially within the context of the framework being applied. The
main target of this methodology framework in the sixties was to develop
large scale functional business systems in an age of large scale business
conglomerates. Information systems activities revolved around heavy data
processing and number crunching routines.
Methodologies, processes, and frameworks range from specific proscriptive
steps that can be used directly by an organization in day to day work, to
flexible frameworks that an organization uses to generate a custom set of
steps tailored to the needs of a specific project or group. In some cases a
sponsor or maintenance organization distributes an official set of
documents that describe the process.
Several software development approaches have been used since the origin of
information technology, in two main categories. Typically an approach or a
combination of approaches is chosen by management or a development team.
Traditional methodologies such as waterfall that have distinct phases are
sometimes known as software development life cycle SDLC methodologies,
though this term could also be used more generally to refer to any
methodology. A project could last for years and years, or you could zip
right through. You plan for the worst. A life cycle approach with distinct
phases is in contrast to Agile approaches which define a process of
iteration, but where design, construction, and deployment of different
pieces can occur simultaneously.
Although the word optimization shares the same root as optimal, it is rare
for the process of optimization to produce a truly optimal system. The
optimized system will typically only be optimal in one application or for
one audience. One might reduce the amount of time that a program takes to
perform some task at the price of making it consume more memory. In an
application where memory space is at a premium, one might deliberatly
choose a slower algorithm in order to use less memory. Often there is no
one size fits all design which works well in all cases, so engineers make
trade offs to optimize the attributes of greatest interest. Additionally,
the effort required to make a piece of software completely optimal incapable of
any further improvement is almost always more than is reasonable for the
benefits that would be accrued; so the process of optimization may be halted
before a completely optimal solution has been reached. Fortunately, it is often
the case that the greatest improvements come early in the process. Optimization
can occur at a number of levels. Typically the higher levels have greater
impact, and are harder to change later on in a project, requiring significant
changes or a complete rewrite if they need to be changed. Thus optimization can
typically proceed via refinement from higher to lower, with initial gains being
larger and achieved with less work, and later gains being smaller and requiring
more work. However, in some cases overall performance depends on performance of
very low level portions of a program, and small changes at a late stage or
early consideration of low level details can have outsized impact. Typically
some consideration is given to efficiency throughout a project though this
varies significantly but major optimization is often considered a refinement
to be done late, if ever. On longer running projects there are typically
cycles of optimization, where improving one area reveals limitations in
another, and these are typically curtailed when performance is acceptable or
gains become too small or costly. As performance is part of the specification
of a program a program that is unusably slow is not fit for purpose: a video
game with sixty Hertz is acceptable, but six frames per second is unacceptably
choppy performance is a consideration from the start, to ensure that the
system is able to deliver sufficient performance, and early prototypes need to
have roughly acceptable performance for there to be confidence that the final
system will, with optimization, achieve acceptable performance. This is
sometimes omitted in the belief that optimization can always be done later,
resulting in prototype systems that are far too slow often by an order of
magnitude or more and systems that ultimately are failures because they
architecturally cannot achieve their performance goals, such as the Intel four
hundred thirty two; or ones that take years of work to achieve acceptable
performance, such as Java in nineteen ninety five, which only achieved
acceptable performance with hot spot. The degree to which performance changes
between prototype and production system, and how amenable it is to
optimization, can be a significant source of uncertainty and risk. The highest
level, the design may be optimized to make best use of the available resources,
given goals, constraints, and expected use/load. The architectural design of a
system overwhelmingly affects its performance. For example, a system that is
network latency bound where network latency is the main constraint on overall
performance would be optimized to minimize network trips, ideally making a
single request or no requests, as in a push protocol rather than multiple
roundtrips. Choice of design depends on the goals: when designing a compiler,
if fast compilation is the key priority, a one-pass compiler is faster than a
multi pass compiler assuming same work, but if speed of output code is the
goal, a slower multi pass compiler fulfills the goal better, even though it
takes longer itself. Choice of platform and programming language occur at
this level, and changing them frequently requires a complete rewrite, though a
modular system may allow rewrite of only some component for example, a Python
program may rewrite performance critical sections in C. In a distributed
system, choice of architecture client server, peer to peer, etc. occurs at
the design level, and may be difficult to change, particularly if all
components cannot be replaced in sync, old clients.

